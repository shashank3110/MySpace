{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yoga_Text_to_Class_Predict.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOP8R3M89zq2btByAfOSOvX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shashank3110/MySpace/blob/master/Yoga_Text_to_Class_Predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "b06e1988-6e71-4f03-db26-56cf660d8228",
        "id": "5kf_NZ8bCBgq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNOKS_P2BsAH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "9ba32934-4c4e-48ac-9f72-099dc4029000"
      },
      "source": [
        "!pip show tensorflow"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 2.1.0rc1\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /tensorflow-2.1.0/python3.6\n",
            "Requires: google-pasta, grpcio, wheel, gast, opt-einsum, tensorboard, keras-preprocessing, keras-applications, tensorflow-estimator, absl-py, protobuf, astor, termcolor, six, numpy, wrapt\n",
            "Required-by: tensorflow-federated, stable-baselines, magenta, fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9KkN-mnym1J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "85a3df02-4d66-4471-b75d-7af567c5ed5d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEBrQIh9yu_X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4d054793-6c2f-4bd6-c972-5f615a0c5529"
      },
      "source": [
        "% cd /content/drive/My Drive/yoga_txt/\n",
        "! unzip text.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/yoga_txt\n",
            "Archive:  text.zip\n",
            "   creating: keras-text-to-image/demo/data/yoga/txt/\n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/tolasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/vajrasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/bhekasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/camatkarasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/supta baddha konasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/bhujapidasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/marjaryasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/parsva bakasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/parivrtta janu sirsasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/pasasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/virabhadrasana iii.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/astavakrasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/ganda bherundasana.txt  \n",
            "   creating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/\n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/parivrtta trikonasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/marjaryasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/ardha pincha mayurasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/salamba bhujangasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/utthita parsvakonasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/matsyasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/salamba sarvangasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/garudasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/ustrasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/parsva bakasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/camatkarasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/bitilasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/virabhadrasana iii-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/parivrtta janu sirsasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/ganda bherundasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/savasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/sukhasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/urdhva mukha svanasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/malasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/halasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/chaturanga dandasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/agnistambhasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/bhekasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/astavakrasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/ananda balasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/uttana shishosana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/bhujapidasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/vajrasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/pasasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/supta baddha konasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/tolasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/ardha uttanasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/marichyasana iii-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/.ipynb_checkpoints/parsvottanasana-checkpoint.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/matsyasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/savasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/urdhva mukha svanasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/halasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/ustrasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/utthita parsvakonasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/malasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/marichyasana iii.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/parsvottanasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/sukhasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/ananda balasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/agnistambhasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/salamba bhujangasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/salamba sarvangasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/garudasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/chaturanga dandasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/bitilasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/ardha uttanasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/uttana shishosana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/ardha pincha mayurasana.txt  \n",
            "  inflating: keras-text-to-image/demo/data/yoga/txt/parivrtta trikonasana.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xYqaSVz1IOU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "3c9113e7-c006-45f5-908c-1468f711c6ec"
      },
      "source": [
        "% cd /content/drive/My Drive/yoga_txt/keras-text-to-image/demo/data/yoga/txt\n",
        "import os \n",
        "tlist = []\n",
        "classes = []\n",
        "path=\"/content/drive/My Drive/yoga_txt/keras-text-to-image/demo/data/yoga/txt\"\n",
        "files = os.listdir(path)\n",
        "print(files)\n",
        "for fname in files:\n",
        "  if fname.endswith(\".txt\"):\n",
        "    f=open(os.path.join(os.getcwd(),fname),\"r\")\n",
        "    txt = f.read()\n",
        "    for i in range(50):\n",
        "      tlist.append(txt)\n",
        "      classes.append(fname.split(\".\")[0])\n"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/yoga_txt/keras-text-to-image/demo/data/yoga/txt\n",
            "['tolasana.txt', 'vajrasana.txt', 'bhekasana.txt', 'camatkarasana.txt', 'supta baddha konasana.txt', 'bhujapidasana.txt', 'marjaryasana.txt', 'parsva bakasana.txt', 'parivrtta janu sirsasana.txt', 'pasasana.txt', 'virabhadrasana iii.txt', 'astavakrasana.txt', 'ganda bherundasana.txt', '.ipynb_checkpoints', 'matsyasana.txt', 'savasana.txt', 'urdhva mukha svanasana.txt', 'halasana.txt', 'ustrasana.txt', 'utthita parsvakonasana.txt', 'malasana.txt', 'marichyasana iii.txt', 'parsvottanasana.txt', 'sukhasana.txt', 'ananda balasana.txt', 'agnistambhasana.txt', 'salamba bhujangasana.txt', 'salamba sarvangasana.txt', 'garudasana.txt', 'chaturanga dandasana.txt', 'bitilasana.txt', 'ardha uttanasana.txt', 'uttana shishosana.txt', 'ardha pincha mayurasana.txt', 'parivrtta trikonasana.txt']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5J9fnQaNb01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tlist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNDZQ-B13Rnd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.DataFrame(list(zip(tlist,classes)),columns=['text','classes'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuDPbHlP4jWd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "424aa313-43ac-4812-e83a-8bfe4767248a"
      },
      "source": [
        "import nltk\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "def bow_transform(df=None):\n",
        "    '''\n",
        "    Args: df : train/dev/text dataframe\n",
        "    Returns: Bag of Words representation of X.\n",
        "    '''\n",
        "    # if isinstance(df,str):\n",
        "    #   text = df\n",
        "    # else:\n",
        "    text = df['text']\n",
        "    token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
        "    cv = CountVectorizer(lowercase=True,stop_words='english',ngram_range = (1,1),tokenizer = token.tokenize)\n",
        "    cv.fit(text)\n",
        "    text_counts= cv.transform(text).toarray()\n",
        "    vocab = cv.vocabulary_\n",
        "    print(vocab)\n",
        "    #cv_without_stop = CountVectorizer(lowercase=True,stop_words=None,ngram_range = (1,1),tokenizer = token.tokenize)\n",
        "    #text_counts_without_stop=cv_without_stop.fit_transform(df['text']).toarray()\n",
        "    #cv_without_stop.vocabulary_\n",
        "    X = text_counts\n",
        "    return X,cv"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdv6pYmm56cS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "628e846e-8fea-479f-f374-d748c0f35a1c"
      },
      "source": [
        "X,cv = bow_transform(df)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'begin': 36, 'lotus': 211, 'padm': 240, 'sana': 297, 'place': 246, 'palms': 241, 'floor': 130, 'hips': 166, 'spread': 331, 'fingers': 121, 'wide': 397, 'push': 269, 'hands': 154, 'contract': 69, 'abdominal': 5, 'muscles': 223, 'lift': 201, 'legs': 197, 'glutes': 145, 'away': 28, 'kneeling': 190, 'knees': 191, 'inner': 178, 'thighs': 366, 'perpendicular': 245, 'tuck': 381, 'toes': 375, 'press': 258, 'tops': 376, 'feet': 120, 'ground': 148, 'sit': 312, 'heels': 160, 'resting': 285, 'soles': 327, 'directly': 89, 'line': 207, 'shins': 307, 'touching': 378, 'pose': 252, 'straight': 346, 'draw': 94, 'shoulder': 308, 'blades': 43, 'firmly': 124, 'ribs': 289, 'widen': 398, 'collarbone': 64, 'drop': 96, 'shoulders': 309, 'ears': 99, 'tall': 363, 'lengthen': 198, 'tailbone': 361, 'allow': 13, 'arms': 25, 'relax': 277, 'rest': 284, 'soften': 325, 'gaze': 142, 'child': 58, 's': 295, 'bal': 30, 'bring': 50, 'slide': 316, 'forward': 137, 'time': 371, 'chest': 57, 'forehead': 136, 'start': 342, 'high': 162, 'hip': 165, 'separate': 302, 'downward': 92, 'facing': 119, 'dog': 91, 'adho': 9, 'mukha': 222, 'v': 393, 'n': 224, 'elevate': 105, 'leg': 195, 'sky': 315, 'stack': 337, 'corresponding': 71, 'upper': 387, 'heel': 159, 'close': 60, 'buttocks': 51, 'possible': 255, 'remain': 280, 'stacked': 338, 'slowly': 320, 'replace': 281, 'hand': 153, 'upraised': 388, 'flip': 129, 'extend': 112, 'foot': 134, 'mat': 217, 'ball': 33, 'knee': 188, 'bent': 40, 'continue': 68, 'reaching': 275, 'free': 138, 'room': 292, 'slightly': 318, 'downwards': 93, 'head': 157, 'curl': 81, 'supine': 354, 'position': 253, 'bend': 39, 'opening': 233, 'groin': 147, 'keeping': 187, 'overhead': 239, 'interlace': 181, 'flat': 125, 'come': 65, 'garland': 140, 'm': 215, 'l': 192, 'ankles': 18, 'need': 229, 'face': 118, 'work': 401, 'arm': 24, 'elbows': 104, 'create': 75, 'shelf': 304, 'hinge': 164, 'earth': 100, 'play': 249, 'lifting': 203, 'available': 27, 'cross': 77, 'box': 49, 'cakrav': 52, 'k': 186, 'shift': 305, 'weight': 396, 'wrists': 404, 'abdomen': 4, 'pulled': 267, 'spine': 329, 'arched': 22, 'strong': 351, 'cobra': 63, 'crown': 80, 'neck': 228, 'relaxed': 278, 'belly': 38, 'crow': 79, 'preparation': 257, 'lean': 193, 'placing': 247, 'chin': 59, 'look': 209, 'tip': 373, 'torso': 377, 'upright': 389, 'snug': 322, 'opposite': 236, 'extended': 113, 'stretch': 350, 'try': 380, 'inside': 179, 'twist': 385, 'sweep': 359, 'ear': 98, 'hold': 167, 'outside': 237, 'edge': 102, 'using': 392, 'like': 205, 'crank': 72, 'help': 161, 'turn': 383, 'revolved': 287, 'squatting': 334, 'toe': 374, 'balance': 31, 'meet': 219, 'reach': 273, 'wrap': 402, 'respective': 283, 'met': 220, 'wrist': 403, 'inhale': 175, 'elongate': 106, 'exhale': 110, 'deeper': 84, 'heart': 158, 'open': 232, 'standing': 341, 'rooted': 293, 'raised': 272, 'parallel': 242, 'thighbone': 365, 'presses': 260, 'actively': 8, 'opposing': 235, 'directions': 88, 'bandhas': 34, 'engaged': 107, 'squared': 332, 'pelvis': 244, 'positioned': 254, 'relatively': 276, 'easy': 101, 'sukh': 353, 'make': 216, 'slip': 319, 'underneath': 386, 'rests': 286, '90': 3, 'degree': 85, 'angle': 15, 'hook': 169, 'simultaneously': 311, 'leaning': 194, 'lowering': 214, 'squeeze': 335, 'use': 390, 'pressure': 262, 'air': 11, 'grounded': 149, 'narrow': 225, 'straighten': 347, 'send': 301, 'higher': 163, 'taking': 362, 'tiny': 372, 'hop': 171, 'lifts': 204, 'small': 321, 'arch': 21, 'seated': 300, 'half': 151, 'ardha': 23, 'forearms': 135, 'body': 46, 'rolled': 291, 'comfortably': 66, 'evenly': 109, 'splayed': 330, 'flop': 131, 'eyes': 117, 'closed': 61, 'inward': 183, 'prone': 263, 'supported': 356, 'equally': 108, 'rotated': 294, 'ribcage': 288, 'lifted': 202, 'slight': 317, 'thoracic': 367, 'backbend': 29, 'joints': 185, 'natural': 227, 'extension': 116, 'tucked': 382, 'fully': 139, 'supporting': 357, 'lower': 213, 'interlaced': 182, 'flexibility': 128, 'allows': 14, 'injure': 176, 'width': 400, 'apart': 19, 'narrowed': 226, 'hardened': 156, 'puff': 266, 'pressed': 259, 'center': 56, 'protrude': 264, 'sharply': 303, 'long': 208, 'base': 35, 'pointed': 251, 'turned': 384, 'outward': 238, 'joint': 184, 'elbow': 103, 'creases': 74, 'squeezing': 336, 'neutral': 231, 'flexed': 127, 'advanced': 10, 'practitioners': 256, 'drops': 97, 'careful': 54, 'strain': 348, 'harden': 155, 'throat': 368, 'depending': 86, 'warrior': 395, 'ii': 172, 'rabhadr': 271, 'stays': 344, 'static': 343, 'folded': 133, 'crease': 73, 'bicep': 42, 'reaches': 274, 'thigh': 364, 'support': 355, 'wider': 399, 'gently': 144, 'snugly': 323, 'anjali': 16, 'mudra': 221, 'salutation': 296, 'seal': 299, 'resist': 282, 'soft': 324, 'staff': 339, 'da': 83, 'sitting': 313, 'bone': 47, 'grounding': 150, 'flex': 126, 'activated': 6, 'leverage': 200, 'want': 394, 'shin': 306, 'catch': 55, 'fingertips': 122, 'pyramid': 270, 'fold': 132, 'squaring': 333, 'simple': 310, 'legged': 196, 'track': 379, 'grip': 146, 'sole': 326, 'difficultly': 87, 'holding': 168, 'loop': 210, 'strap': 349, 'coaxing': 62, 'lengthening': 199, 'releasing': 279, 'tail': 360, 'extending': 114, 'skull': 314, 'pelvic': 243, 'bowl': 48, 'contracted': 70, 'interiorly': 180, 'pubis': 265, 'right': 290, 'inhalation': 174, 'sternum': 345, 'attached': 26, 'active': 7, 'matchstick': 218, 'crossed': 78, 'ankle': 17, 'hooked': 170, 'calf': 53, 'balanced': 32, 'crook': 76, 'approximately': 20, '5': 1, 'inches': 173, 'inline': 177, 'gentle': 143, 'sway': 358, 'low': 212, 'tilt': 370, 'halfway': 152, 'connected': 67, 'pressing': 261, 'pulling': 268, 'firm': 123, 'blanket': 44, 'used': 391, 'needed': 230, 'curve': 82, 'planted': 248, 'sphinx': 328, 'bhuja': 41, 'gasana': 141, 'distributed': 90, 'stance': 340, 'scissor': 298, '45': 0, '60': 2, 'aligned': 12, 'kneecap': 189, 'opens': 234, 'extends': 115, 'limited': 206, 'block': 45, 'beginning': 37, 'students': 352, 'experienced': 111, 'thumb': 369, 'drishti': 95, 'point': 250}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihJoBTx05-ZU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "76bd6933-60e7-415e-dd5f-41a7bd6466a8"
      },
      "source": [
        "print(X.shape)\n",
        "print(X[3])"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1700, 405)\n",
            "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
            " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gRDnE0L6vDn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "816768fe-5f4d-4a5b-8ce6-75bd8b3d943d"
      },
      "source": [
        "Y = pd.get_dummies(df['classes'],columns=df[\"classes\"].unique())\n",
        "print(Y)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      agnistambhasana  ananda balasana  ...  vajrasana  virabhadrasana iii\n",
            "0                   0                0  ...          0                   0\n",
            "1                   0                0  ...          0                   0\n",
            "2                   0                0  ...          0                   0\n",
            "3                   0                0  ...          0                   0\n",
            "4                   0                0  ...          0                   0\n",
            "...               ...              ...  ...        ...                 ...\n",
            "1695                0                0  ...          0                   0\n",
            "1696                0                0  ...          0                   0\n",
            "1697                0                0  ...          0                   0\n",
            "1698                0                0  ...          0                   0\n",
            "1699                0                0  ...          0                   0\n",
            "\n",
            "[1700 rows x 34 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5uS-_QR7lyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Embedding,GRU\n",
        "#  Subclassed model (18/1/2020)\n",
        "# class Text_Model(Model):\n",
        "#     def __init__(self):\n",
        "#         super(Text_Model,self).__init__()\n",
        "#         self.l1 =Dense(128,activation='relu')#input_shape=()\n",
        "#         self.l2 =Dense(64,activation='relu')\n",
        "#         self.l3 =Dense(34,activation='softmax')\n",
        "#     def call(self,inputs):\n",
        "#         # print(\"Reached Here !!!\")\n",
        "#         x= inputs\n",
        "#         # print(\"Not yet!!!\")\n",
        "#         output = self.l3(self.l2(self.l1(x)))\n",
        "#         return output\n",
        "\n",
        "# Here we are using Functional Model as we cannot save subclassed model weights\n",
        "# as .h5 file (18/1/2020)\n",
        "model = Sequential()\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dense(34,activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsBGlsckGFS5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7385307e-15a6-4b6b-9809-dbc66a4c247e"
      },
      "source": [
        "print(X.shape,Y.shape)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1700, 405) (1700, 34)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxikjqhH7yiX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.001\n",
        "batch_size=100\n",
        "epochs = 10\n",
        "#model = Text_Model()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y,test_size= 0.2,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iP5VKweqA7l6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "b737a842-fa88-4432-e681-74315b72b18a"
      },
      "source": [
        "\n",
        "opt = tf.optimizers.RMSprop(learning_rate= learning_rate)\n",
        "model.compile(optimizer=opt,loss=tf.keras.losses.CategoricalCrossentropy(),metrics=['accuracy'])\n",
        "y_train_tensor = tf.convert_to_tensor(y_train.to_numpy(), dtype=tf.float32)\n",
        "\n",
        "X_train_tensor = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "model.fit(X_train_tensor,y_train_tensor,batch_size=batch_size,epochs=epochs,validation_split=0.2)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1088 samples, validate on 272 samples\n",
            "Epoch 1/10\n",
            "1088/1088 [==============================] - 0s 405us/sample - loss: 2.6643 - accuracy: 0.6085 - val_loss: 1.8320 - val_accuracy: 0.9853\n",
            "Epoch 2/10\n",
            "1088/1088 [==============================] - 0s 55us/sample - loss: 1.2824 - accuracy: 0.9945 - val_loss: 0.8065 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "1088/1088 [==============================] - 0s 49us/sample - loss: 0.5455 - accuracy: 1.0000 - val_loss: 0.3295 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "1088/1088 [==============================] - 0s 51us/sample - loss: 0.2231 - accuracy: 1.0000 - val_loss: 0.1349 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "1088/1088 [==============================] - 0s 46us/sample - loss: 0.0938 - accuracy: 1.0000 - val_loss: 0.0580 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "1088/1088 [==============================] - 0s 45us/sample - loss: 0.0406 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "1088/1088 [==============================] - 0s 48us/sample - loss: 0.0181 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "1088/1088 [==============================] - 0s 44us/sample - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "1088/1088 [==============================] - 0s 43us/sample - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "1088/1088 [==============================] - 0s 47us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3a70266080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4JmQHI9OOKc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "3fce7ba4-b8fe-4ff4-fdcf-387be6c99868"
      },
      "source": [
        "y_test_tensor = tf.convert_to_tensor(y_test.to_numpy(), dtype=tf.float32)\n",
        "\n",
        "X_test_tensor = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
        "model.evaluate(X_test_tensor,y_test_tensor)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "340/340 [==============================] - 0s 88us/sample - loss: 0.0015 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0014992328675682931, 1.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlNQu5lbGOEh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "705fa0ac-f80d-44f7-ca98-05ae7c095e72"
      },
      "source": [
        "sample= 'Keep the heart open and the gaze should be slightly over the top shoulder. On the inhale, elongate the spine and on the exhale take the twist slightly deeper.From Revolved Squatting Toe Balance</a>, bring the top arm up and around the back to meet the bottom arm that will reach under and wrap around its respective knee to be met at the wrist by the top hand.'\n",
        "print(isinstance(sample,str))\n",
        "sample = cv.transform([sample]).toarray()\n",
        "print(sample.shape)\n",
        "y_predicted = model.predict(sample)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "(1, 405)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZtR7mciSv08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "#print(np.argmax(y_predicted),sample)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NyK1M3GhPfG5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "bd209309-2886-4f97-d5d9-0d2916ddc7c7"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_36 (Dense)             multiple                  51968     \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             multiple                  8256      \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             multiple                  2210      \n",
            "=================================================================\n",
            "Total params: 62,434\n",
            "Trainable params: 62,434\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIwOveUwUifH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41ad7c1e-867d-42dd-b027-391617bdd833"
      },
      "source": [
        "Y.columns[np.argmax(y_predicted)] "
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pasasana'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1w8iCsMYni3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime \n",
        "dt_string = datetime.datetime.now().strftime(\"%d%m%Y_%H%M_%S\")\n",
        "model.save(\"/content/drive/My Drive/yoga_txt/text_model_\"+dt_string+\".h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gz5bbax4bPm6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "daf0b84f-0e1b-4a1d-a803-4f46d48e456f"
      },
      "source": [
        "#Using Functional instead of subclassed model and model save and load code added.\n",
        "sample2=\"From Box or Cakravākāsana, the ribcage is lifted with a gentle sway in the low back. The eyes are soft and the gaze is to the sky.  The tailbone lifts up into dog tilt.\"\n",
        "sample2 = cv.transform([sample2]).toarray()\n",
        "model.load_weights(\"/content/drive/My Drive/yoga_txt/text_model_18012020_1127_26.h5\")\n",
        "print(Y.columns[np.argmax(model.predict(sample2))])"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bitilasana\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}